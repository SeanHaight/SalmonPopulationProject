{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc5b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87be65ff",
   "metadata": {},
   "source": [
    "# Sean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85478df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the relevant Python modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15a98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the relevant data\n",
    "Salmon = pd.read_excel(\"Data/ZooPlanktonPerryData.xlsx\", 5)\n",
    "oldSSTs = pd.read_csv(\"Data/SSTs\")\n",
    "Salinity = pd.read_csv(\"Data/Entrance_Island_-_Average_Monthly_Sea_Surface_Salinities_1936-2023.csv\")\n",
    "Catches = pd.read_excel(\"Data/Copy of recreational reported fishery catch, 1953-2012.xlsx\")\n",
    "SeaLevel = pd.read_csv(\"Data/SeaLevel_Cherry_annualMean.txt\", sep=\";\")\n",
    "xl_file = pd.ExcelFile('Data/ZooPlanktonPerryData.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0278c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aycin\\AppData\\Local\\Temp\\ipykernel_14396\\1967338990.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zoos[\"Year\"] = anom[\"Year\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "Salmon = Salmon.rename(columns={\"Ocean Entry Year\":\"Year\"})\n",
    "\n",
    "#For each year I want a list with the SSTs for the months in ascending order. \n",
    "SSTsList = []\n",
    "for year in oldSSTs[\"Year\"].unique():\n",
    "    SSTsList.append([year] + oldSSTs[oldSSTs[\"Year\"] == year][\"SST\"].tolist())\n",
    "\n",
    "SSTs = pd.DataFrame(SSTsList, columns=[\"Year\", \"SST Jan.\", \"SST Feb.\", \"SST Mar.\", \"SST Apr.\", \"SST May\", \"SST Jun.\", \"SST Jul.\", \"SST Aug\", \"SST Sep.\", \"SST Oct.\", \"SST Nov.\", \"SST Dec.\"])\n",
    "\n",
    "#Extract the zoo plankton anomalies from the excel sheet\n",
    "Original_Salmon_Sheets = {sheet_name: xl_file.parse(sheet_name) \n",
    "          for sheet_name in xl_file.sheet_names}\n",
    "\n",
    "anom = Original_Salmon_Sheets['3. Zooplankton anomalies']\n",
    "anom = anom[6:]\n",
    "zoos = anom[anom.columns[3:]]\n",
    "zoos[\"Year\"] = anom[\"Year\"].astype(int)\n",
    "\n",
    "#Grab the relevant years from Salinity\n",
    "Salinity = Salinity[55:] \n",
    "Salinity = Salinity.rename(columns={\"ENTRANCE ISLAND LIGHTSTATION: AVERAGE MONTHLY SEA SURFACE SALINITIES (PSU)\":\"Year\"})\n",
    "Salinity = Salinity['Year'].astype(int)\n",
    "\n",
    "#Next is Catches\n",
    "ModernCatches = Catches[Catches[\"YEAR\"] >= 1990]\n",
    "CohoCatches = ModernCatches[ModernCatches[\"SPECIES_DESC\"] == \"COHO SALMON\"]\n",
    "ChinookCatches = ModernCatches[ModernCatches[\"SPECIES_DESC\"] == \"CHINOOK SALMON\"]\n",
    "cohoAnnualCatchList = []\n",
    "chinookAnnualCatchList = []\n",
    "yearList = []\n",
    "for year in CohoCatches[\"YEAR\"].unique():\n",
    "    cohoAnnualCatchList.append(CohoCatches[CohoCatches[\"YEAR\"] == year][\"PIECES\"].sum())\n",
    "    chinookAnnualCatchList.append(ChinookCatches[ChinookCatches[\"YEAR\"] == year][\"PIECES\"].sum())\n",
    "    yearList.append(year)\n",
    "Catches = pd.DataFrame({\"Coho\": cohoAnnualCatchList, \"Chinook\": chinookAnnualCatchList, \"Year\": yearList})\n",
    "#Sealevel\n",
    "SeaLevel = SeaLevel.drop(['Y', '000'], axis=1)\n",
    "SeaLevel= SeaLevel.rename(columns={' 1985': \"Year\",'  6945': \"Sea Level\"}, errors=\"raise\")\n",
    "SeaLevel = SeaLevel[4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ce32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the relevant data into a single data frame\n",
    "newFrame1 = pd.merge(Salmon, SSTs, on=\"Year\", how=\"outer\")\n",
    "newFrame2 = pd.merge(newFrame1, zoos, on=\"Year\", how=\"outer\")\n",
    "newFrame3 = pd.merge(newFrame2, Salinity, on=\"Year\", how=\"outer\")\n",
    "newFrame4 = pd.merge(newFrame3, Catches, on=\"Year\", how=\"outer\")\n",
    "AllData = pd.merge(newFrame4, SeaLevel, on=\"Year\", how=\"outer\")\n",
    "AllData[[\"Cowichan Chinook\", \"Harrison Chinook\", \"Puntledge Chinook\"]] = AllData[[\"Cowichan Chinook\", \"Harrison Chinook\", \"Puntledge Chinook\"]].fillna(0)\n",
    "#Drop the years we have no viability data for\n",
    "AllData = AllData.drop([28, 29, 30, 31, 32, 33])\n",
    "AllDataNoNull = AllData.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd154575",
   "metadata": {},
   "source": [
    "## Obtained Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f172f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Cowichan Chinook</th>\n",
       "      <th>Harrison Chinook</th>\n",
       "      <th>Puntledge Chinook</th>\n",
       "      <th>Big Qualicum Coho</th>\n",
       "      <th>SST Jan.</th>\n",
       "      <th>SST Feb.</th>\n",
       "      <th>SST Mar.</th>\n",
       "      <th>SST Apr.</th>\n",
       "      <th>SST May</th>\n",
       "      <th>...</th>\n",
       "      <th>Natantia</th>\n",
       "      <th>NonCalCops</th>\n",
       "      <th>Ostracoda</th>\n",
       "      <th>PolychaetPelagic</th>\n",
       "      <th>Pteropods</th>\n",
       "      <th>Repantia</th>\n",
       "      <th>Siphonophorae</th>\n",
       "      <th>Coho</th>\n",
       "      <th>Chinook</th>\n",
       "      <th>Sea Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014246</td>\n",
       "      <td>10.860983</td>\n",
       "      <td>12.025331</td>\n",
       "      <td>11.728321</td>\n",
       "      <td>11.119489</td>\n",
       "      <td>9.948300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102015</td>\n",
       "      <td>0.242330</td>\n",
       "      <td>0.297214</td>\n",
       "      <td>0.255998</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>-0.604888</td>\n",
       "      <td>0.391865</td>\n",
       "      <td>217199.0</td>\n",
       "      <td>114942.0</td>\n",
       "      <td>6988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>11.910243</td>\n",
       "      <td>12.317101</td>\n",
       "      <td>12.166986</td>\n",
       "      <td>11.192175</td>\n",
       "      <td>10.135995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163304</td>\n",
       "      <td>0.248062</td>\n",
       "      <td>0.278687</td>\n",
       "      <td>-0.063418</td>\n",
       "      <td>-0.024925</td>\n",
       "      <td>0.211126</td>\n",
       "      <td>0.247333</td>\n",
       "      <td>213163.0</td>\n",
       "      <td>154268.0</td>\n",
       "      <td>7081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>0.013055</td>\n",
       "      <td>12.177850</td>\n",
       "      <td>12.481543</td>\n",
       "      <td>12.182488</td>\n",
       "      <td>11.857747</td>\n",
       "      <td>10.362404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159563</td>\n",
       "      <td>0.238723</td>\n",
       "      <td>0.374939</td>\n",
       "      <td>0.089059</td>\n",
       "      <td>0.701012</td>\n",
       "      <td>0.770283</td>\n",
       "      <td>0.089499</td>\n",
       "      <td>16335.0</td>\n",
       "      <td>160780.0</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Cowichan Chinook  Harrison Chinook  Puntledge Chinook  \\\n",
       "6  1996          0.008811          0.010038           0.000000   \n",
       "7  1997          0.008294          0.023246           0.004286   \n",
       "8  1998          0.010999          0.008297           0.017847   \n",
       "\n",
       "   Big Qualicum Coho   SST Jan.   SST Feb.   SST Mar.   SST Apr.    SST May  \\\n",
       "6           0.014246  10.860983  12.025331  11.728321  11.119489   9.948300   \n",
       "7           0.004293  11.910243  12.317101  12.166986  11.192175  10.135995   \n",
       "8           0.013055  12.177850  12.481543  12.182488  11.857747  10.362404   \n",
       "\n",
       "   ...  Natantia  NonCalCops  Ostracoda  PolychaetPelagic  Pteropods  \\\n",
       "6  ...  0.102015    0.242330   0.297214          0.255998   0.019095   \n",
       "7  ...  0.163304    0.248062   0.278687         -0.063418  -0.024925   \n",
       "8  ...  0.159563    0.238723   0.374939          0.089059   0.701012   \n",
       "\n",
       "   Repantia  Siphonophorae      Coho   Chinook  Sea Level  \n",
       "6 -0.604888       0.391865  217199.0  114942.0     6988.0  \n",
       "7  0.211126       0.247333  213163.0  154268.0     7081.0  \n",
       "8  0.770283       0.089499   16335.0  160780.0     7065.0  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllDataNoNull.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbbb95",
   "metadata": {},
   "source": [
    "# Roy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc50648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "832a39df",
   "metadata": {},
   "source": [
    "# Andrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15765138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbf25c2c",
   "metadata": {},
   "source": [
    "# Aycin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e92460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f7e82",
   "metadata": {},
   "source": [
    "Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de76eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Years we concerned with \n",
    "start_year=1990\n",
    "end_year=2017\n",
    "year_range = range(start_year, end_year+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672868eb",
   "metadata": {},
   "source": [
    " Target Data - Salmon Survivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589df7e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Read ZooPlanktonPerryData file\n",
    "##obtain SalmonSurvivals_data\n",
    "            #Take years less than or equal to 2017\n",
    "                            #last row (year 2018) has only NaN\n",
    "\n",
    "\n",
    "file_path = \"Data/ZooPlanktonPerryData.xlsx\"\n",
    "selected_sheet = \"5. Salmon marine survivals\"  \n",
    "df = pd.read_excel(file_path, sheet_name=selected_sheet)\n",
    "SalmonSurvivals_data = df[df[\"Ocean Entry Year\"]<=2017]\n",
    "\n",
    "\n",
    "#Rename the columns \n",
    "abbreviation_mapping = {\n",
    "    'Ocean Entry Year': 'year',\n",
    "    'Cowichan Chinook': 'Cow_Ch',\n",
    "    'Harrison Chinook': 'Har_Ch',\n",
    "    'Puntledge Chinook': 'Pun_Ch',\n",
    "    'Big Qualicum Coho': 'BQ_Coho'\n",
    "}\n",
    "\n",
    "salmonSurvivals = SalmonSurvivals_data.rename(columns=abbreviation_mapping)\n",
    "\n",
    "\n",
    "# List of salmon types \n",
    "year_column = 'year'\n",
    "salmonTypes_List =  [col for col in salmonSurvivals.columns if col != year_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505320eb",
   "metadata": {},
   "source": [
    "Data Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01567a6",
   "metadata": {},
   "source": [
    "Total Zooplankton Biomasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a27f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ZooPlanktonPerryData file\n",
    "\n",
    "##obtain  plankBiomass_data   \n",
    "###take the years less than 2017 \n",
    "###we drop columns that do not give biomass of zooplanktons\n",
    "file_path = \"Data/ZooPlanktonPerryData.xlsx\"\n",
    "selected_sheet = \"1. Zooplankton Biomass data\"  \n",
    "df = pd.read_excel(file_path, sheet_name=selected_sheet)\n",
    "df= df[df[\"yr\"]<=2017]\n",
    "plankBiomass_data=df.drop(columns=['key', 'survey', 'region', 'event', 'net', 'station', 'lon', 'lat', 'mon', 'day', 'time',  'twilight', 'net.type', 'diam.m', 'mesh.um', 'startz.m', 'endz.m','botz.m',\n",
    "       'volfilt.m3'])\n",
    "\n",
    "##  BiomassDefs      (if info on column names is needed)\n",
    "selected_sheet = \"2. Biomass data definitions\"  \n",
    "BiomassDefs = pd.read_excel(file_path, sheet_name=selected_sheet)\n",
    "\n",
    "\n",
    "\n",
    "## Create a new DataFrame which contains years and corresponding total biomasses mean\n",
    "#Calculate average Total Biomass for each year inside the common year range\n",
    "#drop duplicates\n",
    "#reset index\n",
    "\n",
    "totalBiomass_av= pd.DataFrame()\n",
    "\n",
    "totalBiomass_av['year']= plankBiomass_data['yr']\n",
    "totalBiomass_av['Av_totalBiomass']= plankBiomass_data.groupby('yr')['Total.Biomass'].transform('mean')\n",
    "totalBiomass_av.drop_duplicates(inplace=True)\n",
    "totalBiomass_av.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Create a new DataFrame for averaged values\n",
    "#Group by 'yr' and calculate the annual mean of Zooplanktons\n",
    "#drop duplicates\n",
    "#rename the columns for convenienve\n",
    "#reset_index\n",
    "\n",
    "plankBiomassMean = pd.DataFrame()\n",
    "\n",
    "for column in plankBiomass_data.columns:\n",
    "    if column in ['yr', 'region']:\n",
    "        plankBiomassMean[column] = plankBiomass_data[column]\n",
    "    else:\n",
    "        name = 'Av_' + column\n",
    "        plankBiomassMean[name] = plankBiomass_data.groupby('yr')[column].transform('mean')\n",
    "\n",
    "\n",
    "plankBiomassMean.drop_duplicates(subset=['yr'], inplace=True)\n",
    "plankBiomassMean.rename(columns={'yr': 'year', 'Av_Total.Biomass': 'Av_totalBiomass'},  inplace=True)\n",
    "plankBiomassMean.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616dfc0",
   "metadata": {},
   "source": [
    "### Obtained Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plankBiomassMean.head(3))\n",
    "display(totalBiomass_av.head(3))\n",
    "#Note: data of totalBiomass_av appears in plankBiomassMean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa86d13",
   "metadata": {},
   "source": [
    "Sea Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the Annual Mean Sea Levels\n",
    "        #there are data of four ports\n",
    "#Take the years between start_year and end_year\n",
    "#Take the positive values (non existent data entered as -99999\n",
    "#drop the columns 2 and 3 to keep year and sea level measurement\n",
    "#rename the column that contains Sea Level measurement\n",
    "\n",
    "\n",
    "file_path=\"Data/SeaLevel_Point_Atkinson193.txt\"\n",
    "df=pd.read_csv(file_path, header=None,delimiter=';')\n",
    "df= df[(df[0] >= start_year) & (df[0] <= end_year) & (df[1]>=0)].drop(columns=[2,3])\n",
    "seaLevelPointA_clean =df.rename(columns={0: 'year', 1: 'SeaLevel_Point_Atkinson'})\n",
    "#missing year 1997\n",
    "\n",
    "file_path=\"Data/SeaLevel_Port_Angeles2127.txt\"\n",
    "df =pd.read_csv(file_path, header=None,delimiter=';')\n",
    "df= df[(df[0] >= start_year) & (df[0] <= end_year) & (df[1]>=0)].drop(columns=[2,3])\n",
    "seaLevelPortA_clean= df.rename(columns={0: 'year', 1: 'SeaLevel_Port_Angeles'})\n",
    "#no missing year\n",
    "\n",
    "file_path=\"Data/SeaLevel_Campbell_River1323.txt\"\n",
    "df=pd.read_csv(file_path, header=None,delimiter=';')\n",
    "df= df[(df[0] >= start_year) & (df[0] <= end_year) & (df[1]>=0)].drop(columns=[2,3])\n",
    "seaLevelCampbellR_clean= df.rename(columns={0: 'year', 1: 'SeaLevel_Campbell_River'})\n",
    "#missing year 1995 & 1996\n",
    "\n",
    "file_path=\"Data/SeaLevel_Cherry_annualMean.txt\"\n",
    "df= pd.read_csv(file_path, header=None,delimiter=';')\n",
    "df= df[(df[0] >= start_year) & (df[0] <= end_year) & (df[1]>=0)].drop(columns=[2,3])\n",
    "seaLevelCherryP_clean= df.rename(columns={0: 'year', 1: 'SeaLevel_Cherry'})\n",
    "#missing year 1994\n",
    "\n",
    "\n",
    "#Merge the sea Levels\n",
    "#Calculate their average \n",
    "    #missing data is ignored \n",
    "        #note: if a year is missing it's only missing at most one of the ports\n",
    "\n",
    "merged_df= pd.merge(seaLevelPortA_clean, seaLevelPointA_clean, on='year', how='outer')\n",
    "merged_df = pd.merge(merged_df, seaLevelCampbellR_clean, on='year', how='outer')\n",
    "seaLevels = pd.merge(merged_df, seaLevelCherryP_clean, on='year', how='outer')\n",
    "\n",
    "seaLevels['av_SeaLevels']= seaLevels.iloc[:,1:].mean(axis=1, skipna=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa84082",
   "metadata": {},
   "source": [
    "### Obtained Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d557e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaLevels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098e0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a213631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
