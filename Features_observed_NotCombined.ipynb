{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe158a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87be65ff",
   "metadata": {},
   "source": [
    "# Sean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85478df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the relevant Python modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15a98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the relevant data\n",
    "Salmon = pd.read_excel(\"Data/ZooPlanktonPerryData.xlsx\", 5)\n",
    "oldSSTs = pd.read_csv(\"Data/SSTs\")\n",
    "Salinity = pd.read_csv(\"Data/Entrance_Island_-_Average_Monthly_Sea_Surface_Salinities_1936-2023.csv\")\n",
    "Catches = pd.read_excel(\"Data/Copy of recreational reported fishery catch, 1953-2012.xlsx\")\n",
    "SeaLevel = pd.read_csv(\"Data/SeaLevel_Cherry_annualMean.txt\", sep=\";\")\n",
    "xl_file = pd.ExcelFile('Data/ZooPlanktonPerryData.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0278c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aycin\\AppData\\Local\\Temp\\ipykernel_7728\\1967338990.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zoos[\"Year\"] = anom[\"Year\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "Salmon = Salmon.rename(columns={\"Ocean Entry Year\":\"Year\"})\n",
    "\n",
    "#For each year I want a list with the SSTs for the months in ascending order. \n",
    "SSTsList = []\n",
    "for year in oldSSTs[\"Year\"].unique():\n",
    "    SSTsList.append([year] + oldSSTs[oldSSTs[\"Year\"] == year][\"SST\"].tolist())\n",
    "\n",
    "SSTs = pd.DataFrame(SSTsList, columns=[\"Year\", \"SST Jan.\", \"SST Feb.\", \"SST Mar.\", \"SST Apr.\", \"SST May\", \"SST Jun.\", \"SST Jul.\", \"SST Aug\", \"SST Sep.\", \"SST Oct.\", \"SST Nov.\", \"SST Dec.\"])\n",
    "\n",
    "#Extract the zoo plankton anomalies from the excel sheet\n",
    "Original_Salmon_Sheets = {sheet_name: xl_file.parse(sheet_name) \n",
    "          for sheet_name in xl_file.sheet_names}\n",
    "\n",
    "anom = Original_Salmon_Sheets['3. Zooplankton anomalies']\n",
    "anom = anom[6:]\n",
    "zoos = anom[anom.columns[3:]]\n",
    "zoos[\"Year\"] = anom[\"Year\"].astype(int)\n",
    "\n",
    "#Grab the relevant years from Salinity\n",
    "Salinity = Salinity[55:] \n",
    "Salinity = Salinity.rename(columns={\"ENTRANCE ISLAND LIGHTSTATION: AVERAGE MONTHLY SEA SURFACE SALINITIES (PSU)\":\"Year\"})\n",
    "Salinity = Salinity['Year'].astype(int)\n",
    "\n",
    "#Next is Catches\n",
    "ModernCatches = Catches[Catches[\"YEAR\"] >= 1990]\n",
    "CohoCatches = ModernCatches[ModernCatches[\"SPECIES_DESC\"] == \"COHO SALMON\"]\n",
    "ChinookCatches = ModernCatches[ModernCatches[\"SPECIES_DESC\"] == \"CHINOOK SALMON\"]\n",
    "cohoAnnualCatchList = []\n",
    "chinookAnnualCatchList = []\n",
    "yearList = []\n",
    "for year in CohoCatches[\"YEAR\"].unique():\n",
    "    cohoAnnualCatchList.append(CohoCatches[CohoCatches[\"YEAR\"] == year][\"PIECES\"].sum())\n",
    "    chinookAnnualCatchList.append(ChinookCatches[ChinookCatches[\"YEAR\"] == year][\"PIECES\"].sum())\n",
    "    yearList.append(year)\n",
    "Catches = pd.DataFrame({\"Coho\": cohoAnnualCatchList, \"Chinook\": chinookAnnualCatchList, \"Year\": yearList})\n",
    "#Sealevel\n",
    "SeaLevel = SeaLevel.drop(['Y', '000'], axis=1)\n",
    "SeaLevel= SeaLevel.rename(columns={' 1985': \"Year\",'  6945': \"Sea Level\"}, errors=\"raise\")\n",
    "SeaLevel = SeaLevel[4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ce32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the relevant data into a single data frame\n",
    "newFrame1 = pd.merge(Salmon, SSTs, on=\"Year\", how=\"outer\")\n",
    "newFrame2 = pd.merge(newFrame1, zoos, on=\"Year\", how=\"outer\")\n",
    "newFrame3 = pd.merge(newFrame2, Salinity, on=\"Year\", how=\"outer\")\n",
    "newFrame4 = pd.merge(newFrame3, Catches, on=\"Year\", how=\"outer\")\n",
    "AllData = pd.merge(newFrame4, SeaLevel, on=\"Year\", how=\"outer\")\n",
    "AllData[[\"Cowichan Chinook\", \"Harrison Chinook\", \"Puntledge Chinook\"]] = AllData[[\"Cowichan Chinook\", \"Harrison Chinook\", \"Puntledge Chinook\"]].fillna(0)\n",
    "#Drop the years we have no viability data for\n",
    "AllData = AllData.drop([28, 29, 30, 31, 32, 33])\n",
    "AllDataNoNull = AllData.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd154575",
   "metadata": {},
   "source": [
    "## Obtained Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f172f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Cowichan Chinook</th>\n",
       "      <th>Harrison Chinook</th>\n",
       "      <th>Puntledge Chinook</th>\n",
       "      <th>Big Qualicum Coho</th>\n",
       "      <th>SST Jan.</th>\n",
       "      <th>SST Feb.</th>\n",
       "      <th>SST Mar.</th>\n",
       "      <th>SST Apr.</th>\n",
       "      <th>SST May</th>\n",
       "      <th>...</th>\n",
       "      <th>Natantia</th>\n",
       "      <th>NonCalCops</th>\n",
       "      <th>Ostracoda</th>\n",
       "      <th>PolychaetPelagic</th>\n",
       "      <th>Pteropods</th>\n",
       "      <th>Repantia</th>\n",
       "      <th>Siphonophorae</th>\n",
       "      <th>Coho</th>\n",
       "      <th>Chinook</th>\n",
       "      <th>Sea Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014246</td>\n",
       "      <td>10.860983</td>\n",
       "      <td>12.025331</td>\n",
       "      <td>11.728321</td>\n",
       "      <td>11.119489</td>\n",
       "      <td>9.948300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102015</td>\n",
       "      <td>0.242330</td>\n",
       "      <td>0.297214</td>\n",
       "      <td>0.255998</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>-0.604888</td>\n",
       "      <td>0.391865</td>\n",
       "      <td>217199.0</td>\n",
       "      <td>114942.0</td>\n",
       "      <td>6988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>11.910243</td>\n",
       "      <td>12.317101</td>\n",
       "      <td>12.166986</td>\n",
       "      <td>11.192175</td>\n",
       "      <td>10.135995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163304</td>\n",
       "      <td>0.248062</td>\n",
       "      <td>0.278687</td>\n",
       "      <td>-0.063418</td>\n",
       "      <td>-0.024925</td>\n",
       "      <td>0.211126</td>\n",
       "      <td>0.247333</td>\n",
       "      <td>213163.0</td>\n",
       "      <td>154268.0</td>\n",
       "      <td>7081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>0.013055</td>\n",
       "      <td>12.177850</td>\n",
       "      <td>12.481543</td>\n",
       "      <td>12.182488</td>\n",
       "      <td>11.857747</td>\n",
       "      <td>10.362404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159563</td>\n",
       "      <td>0.238723</td>\n",
       "      <td>0.374939</td>\n",
       "      <td>0.089059</td>\n",
       "      <td>0.701012</td>\n",
       "      <td>0.770283</td>\n",
       "      <td>0.089499</td>\n",
       "      <td>16335.0</td>\n",
       "      <td>160780.0</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Cowichan Chinook  Harrison Chinook  Puntledge Chinook  \\\n",
       "6  1996          0.008811          0.010038           0.000000   \n",
       "7  1997          0.008294          0.023246           0.004286   \n",
       "8  1998          0.010999          0.008297           0.017847   \n",
       "\n",
       "   Big Qualicum Coho   SST Jan.   SST Feb.   SST Mar.   SST Apr.    SST May  \\\n",
       "6           0.014246  10.860983  12.025331  11.728321  11.119489   9.948300   \n",
       "7           0.004293  11.910243  12.317101  12.166986  11.192175  10.135995   \n",
       "8           0.013055  12.177850  12.481543  12.182488  11.857747  10.362404   \n",
       "\n",
       "   ...  Natantia  NonCalCops  Ostracoda  PolychaetPelagic  Pteropods  \\\n",
       "6  ...  0.102015    0.242330   0.297214          0.255998   0.019095   \n",
       "7  ...  0.163304    0.248062   0.278687         -0.063418  -0.024925   \n",
       "8  ...  0.159563    0.238723   0.374939          0.089059   0.701012   \n",
       "\n",
       "   Repantia  Siphonophorae      Coho   Chinook  Sea Level  \n",
       "6 -0.604888       0.391865  217199.0  114942.0     6988.0  \n",
       "7  0.211126       0.247333  213163.0  154268.0     7081.0  \n",
       "8  0.770283       0.089499   16335.0  160780.0     7065.0  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllDataNoNull.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbbb95",
   "metadata": {},
   "source": [
    "# Roy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc50648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "start_date = 1996\n",
    "end_date = 2017\n",
    "\n",
    "#(1) read sea salinity data\n",
    "Salinity_file = pd.read_excel('Data/Entrance_island_salinity.xlsx') \n",
    "\n",
    "#(2) read Pacific decadal oscillation(PDO) data\n",
    "Pdo_file = pd.read_excel('Data/pdo.xlsx','pdo')  \n",
    "\n",
    "#(3) read Fraser river flow data\n",
    "Flow_rate_file = pd.read_excel('Data/Fraser_flow_rate.xlsx','Flow rate')  \n",
    "\n",
    "#(4) read Killer Whale data\n",
    "Whale_file = pd.read_excel('Data/killerwhales_1970to2020.xlsx','killerwhales_1970to2020') \n",
    "\n",
    "#(5) read harbour seal population data\n",
    "Seal_file = pd.read_excel('Data/harbourseals_1970to2020.xlsx','harbourseals_1970to2020')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016ca7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sea salinity is provided monthly, we will calculate yearly average. Also, nonexistent data is marked by 999.99\n",
    "\n",
    "df_salinity = Salinity_file.replace(999.99,np.nan)\n",
    "df_salinity_yr = df_salinity['YEAR']\n",
    "df_salinity_val = df_salinity.drop(['YEAR'],axis=1).mean(axis = 1)\n",
    "df_sea_salinity = pd.DataFrame({'Year':df_salinity_yr,'Avg Sea Salinity':df_salinity_val})\n",
    "df_sea_salinity = df_sea_salinity.loc[(df_sea_salinity['Year'] >= start_date) & (df_sea_salinity['Year'] <= end_date)]\n",
    "df_sea_salinity.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5edb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdo = Pdo_file.loc[(Pdo_file['year'] >= start_date) & (Pdo_file['year'] <= end_date)]\n",
    "df_pdo_clean = df_pdo.rename(columns={'year':'Year'})\n",
    "df_pdo_avg = df_pdo_clean.groupby(['Year']).mean()\n",
    "df_pdo_avg = df_pdo_avg.drop(columns = ['date','month'])\n",
    "\n",
    "\n",
    "df_flow_rate = Flow_rate_file[(Flow_rate_file['Year'] >= start_date) & (Flow_rate_file['Year'] <= end_date) &(Flow_rate_file['PARAM'] == 1)]\n",
    "df_flow_rate = df_flow_rate.drop(columns = ['Â ID','PARAM','MM--DD','SYM','MM--DD.1','SYM.1'])\n",
    "df_flow_rate['Avg flow rate'] = 0.5*(df_flow_rate['MAX']+df_flow_rate['MIN'])\n",
    "df_flow_rate.rename(columns = {'MAX':'Max flow rate','MIN':'Min flow rate'},inplace = True)\n",
    "df_flow_rate.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392d9437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year  Avg Sea Salinity       pdo  Max flow rate  Min flow rate  \\\n",
      "0   1996         26.720833  0.683333         8100.0          675.0   \n",
      "1   1997         25.359167  1.316667        11300.0          788.0   \n",
      "2   1998         27.243333 -0.478333         6710.0          600.0   \n",
      "3   1999         26.195833 -1.843333        11000.0          647.0   \n",
      "4   2000         27.405833 -1.125833         8000.0          470.0   \n",
      "5   2001         28.385000 -1.134167         7140.0          478.0   \n",
      "6   2002         27.663333 -0.439167        10600.0          491.0   \n",
      "7   2003         27.967273  0.381667         7300.0          472.0   \n",
      "8   2004         27.438333 -0.224167         6650.0          560.0   \n",
      "9   2005         27.265000 -0.188333         7460.0          805.0   \n",
      "10  2006         28.180833 -0.350833         7190.0          510.0   \n",
      "11  2007         26.918333 -0.702500        10800.0          560.0   \n",
      "12  2008         27.835833 -1.663333        10200.0          648.0   \n",
      "13  2009         27.345000 -1.031667         7490.0          684.0   \n",
      "14  2010         26.639167 -1.060833         5950.0          738.0   \n",
      "15  2011         24.715455 -1.811667         9850.0          700.0   \n",
      "16  2012         25.620833 -1.733333        11700.0          705.0   \n",
      "17  2013         26.575000 -1.164167        10100.0          696.0   \n",
      "18  2014         26.342500  0.552500         9920.0          605.0   \n",
      "19  2015         26.811667  0.915000         7960.0          844.0   \n",
      "20  2016         26.735000  0.670000         6040.0          756.0   \n",
      "21  2017         25.180000 -0.095833         9720.0          627.0   \n",
      "\n",
      "    Avg flow rate  \n",
      "0          4387.5  \n",
      "1          6044.0  \n",
      "2          3655.0  \n",
      "3          5823.5  \n",
      "4          4235.0  \n",
      "5          3809.0  \n",
      "6          5545.5  \n",
      "7          3886.0  \n",
      "8          3605.0  \n",
      "9          4132.5  \n",
      "10         3850.0  \n",
      "11         5680.0  \n",
      "12         5424.0  \n",
      "13         4087.0  \n",
      "14         3344.0  \n",
      "15         5275.0  \n",
      "16         6202.5  \n",
      "17         5398.0  \n",
      "18         5262.5  \n",
      "19         4402.0  \n",
      "20         3398.0  \n",
      "21         5173.5  \n"
     ]
    }
   ],
   "source": [
    "df_env_factors = pd.merge(df_sea_salinity,df_pdo_avg,on = 'Year',how = 'outer')\n",
    "df_env_factors = pd.merge(df_env_factors, df_flow_rate[['Year','Max flow rate','Min flow rate','Avg flow rate']], on = 'Year', how = 'outer')\n",
    "print(df_env_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ba38d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Avg Sea Salinity</th>\n",
       "      <th>pdo</th>\n",
       "      <th>Max flow rate</th>\n",
       "      <th>Min flow rate</th>\n",
       "      <th>Avg flow rate</th>\n",
       "      <th>Harbour seal</th>\n",
       "      <th>Killer whale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996</td>\n",
       "      <td>26.720833</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>4387.5</td>\n",
       "      <td>39166</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>25.359167</td>\n",
       "      <td>1.316667</td>\n",
       "      <td>11300.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>6044.0</td>\n",
       "      <td>39187</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>27.243333</td>\n",
       "      <td>-0.478333</td>\n",
       "      <td>6710.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3655.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>26.195833</td>\n",
       "      <td>-1.843333</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>5823.5</td>\n",
       "      <td>39190</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>27.405833</td>\n",
       "      <td>-1.125833</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>4235.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>28.385000</td>\n",
       "      <td>-1.134167</td>\n",
       "      <td>7140.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>3809.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002</td>\n",
       "      <td>27.663333</td>\n",
       "      <td>-0.439167</td>\n",
       "      <td>10600.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>5545.5</td>\n",
       "      <td>39190</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003</td>\n",
       "      <td>27.967273</td>\n",
       "      <td>0.381667</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>3886.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2004</td>\n",
       "      <td>27.438333</td>\n",
       "      <td>-0.224167</td>\n",
       "      <td>6650.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3605.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2005</td>\n",
       "      <td>27.265000</td>\n",
       "      <td>-0.188333</td>\n",
       "      <td>7460.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>4132.5</td>\n",
       "      <td>39190</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2006</td>\n",
       "      <td>28.180833</td>\n",
       "      <td>-0.350833</td>\n",
       "      <td>7190.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007</td>\n",
       "      <td>26.918333</td>\n",
       "      <td>-0.702500</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>5680.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008</td>\n",
       "      <td>27.835833</td>\n",
       "      <td>-1.663333</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>5424.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2009</td>\n",
       "      <td>27.345000</td>\n",
       "      <td>-1.031667</td>\n",
       "      <td>7490.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>4087.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010</td>\n",
       "      <td>26.639167</td>\n",
       "      <td>-1.060833</td>\n",
       "      <td>5950.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>3344.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2011</td>\n",
       "      <td>24.715455</td>\n",
       "      <td>-1.811667</td>\n",
       "      <td>9850.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>5275.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012</td>\n",
       "      <td>25.620833</td>\n",
       "      <td>-1.733333</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>6202.5</td>\n",
       "      <td>39190</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013</td>\n",
       "      <td>26.575000</td>\n",
       "      <td>-1.164167</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014</td>\n",
       "      <td>26.342500</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>9920.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>5262.5</td>\n",
       "      <td>39190</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015</td>\n",
       "      <td>26.811667</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>7960.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>4402.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016</td>\n",
       "      <td>26.735000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>3398.0</td>\n",
       "      <td>39190</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>25.180000</td>\n",
       "      <td>-0.095833</td>\n",
       "      <td>9720.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>5173.5</td>\n",
       "      <td>39190</td>\n",
       "      <td>303.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Avg Sea Salinity       pdo  Max flow rate  Min flow rate  \\\n",
       "0   1996         26.720833  0.683333         8100.0          675.0   \n",
       "1   1997         25.359167  1.316667        11300.0          788.0   \n",
       "2   1998         27.243333 -0.478333         6710.0          600.0   \n",
       "3   1999         26.195833 -1.843333        11000.0          647.0   \n",
       "4   2000         27.405833 -1.125833         8000.0          470.0   \n",
       "5   2001         28.385000 -1.134167         7140.0          478.0   \n",
       "6   2002         27.663333 -0.439167        10600.0          491.0   \n",
       "7   2003         27.967273  0.381667         7300.0          472.0   \n",
       "8   2004         27.438333 -0.224167         6650.0          560.0   \n",
       "9   2005         27.265000 -0.188333         7460.0          805.0   \n",
       "10  2006         28.180833 -0.350833         7190.0          510.0   \n",
       "11  2007         26.918333 -0.702500        10800.0          560.0   \n",
       "12  2008         27.835833 -1.663333        10200.0          648.0   \n",
       "13  2009         27.345000 -1.031667         7490.0          684.0   \n",
       "14  2010         26.639167 -1.060833         5950.0          738.0   \n",
       "15  2011         24.715455 -1.811667         9850.0          700.0   \n",
       "16  2012         25.620833 -1.733333        11700.0          705.0   \n",
       "17  2013         26.575000 -1.164167        10100.0          696.0   \n",
       "18  2014         26.342500  0.552500         9920.0          605.0   \n",
       "19  2015         26.811667  0.915000         7960.0          844.0   \n",
       "20  2016         26.735000  0.670000         6040.0          756.0   \n",
       "21  2017         25.180000 -0.095833         9720.0          627.0   \n",
       "\n",
       "    Avg flow rate  Harbour seal  Killer whale  \n",
       "0          4387.5         39166         214.0  \n",
       "1          6044.0         39187         218.0  \n",
       "2          3655.0         39190         216.0  \n",
       "3          5823.5         39190         216.0  \n",
       "4          4235.0         39190         208.0  \n",
       "5          3809.0         39190         200.0  \n",
       "6          5545.5         39190         203.0  \n",
       "7          3886.0         39190         204.0  \n",
       "8          3605.0         39190         220.0  \n",
       "9          4132.5         39190         230.0  \n",
       "10         3850.0         39190         239.0  \n",
       "11         5680.0         39190         240.0  \n",
       "12         5424.0         39190         250.0  \n",
       "13         4087.0         39190         256.0  \n",
       "14         3344.0         39190         261.0  \n",
       "15         5275.0         39190         267.0  \n",
       "16         6202.5         39190         272.0  \n",
       "17         5398.0         39190         275.0  \n",
       "18         5262.5         39190         288.0  \n",
       "19         4402.0         39190         297.0  \n",
       "20         3398.0         39190         302.0  \n",
       "21         5173.5         39190         303.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whale = Whale_file.loc[(Whale_file['Year'] >= start_date) & (Whale_file['Year'] <= end_date)].drop(columns = ['SRKW','srkwSource','nrkwSource'])\n",
    "df_seal = Seal_file.loc[(Seal_file['year'] >= start_date) & (Seal_file['year'] <= end_date)].drop(columns = ['nonSogNt','bcNt']).rename(columns={'year':'Year'})\n",
    "\n",
    "\n",
    "df_whale.reset_index(drop = True, inplace = True)\n",
    "df_seal.reset_index(drop = True, inplace = True)\n",
    "\n",
    "df_pred_factors = pd.merge(df_seal,df_whale, on = 'Year',how = 'outer')\n",
    "df_pred_factors.rename(columns = {'sogNt':'Harbour seal','NRKW':'Killer whale'},inplace = True)\n",
    "df_input_variables = pd.merge(df_env_factors,df_pred_factors,on = 'Year', how = 'outer')\n",
    "df_input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a39df",
   "metadata": {},
   "source": [
    "# Andrew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9bdec1-f728-495d-a437-59164a1beaad",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10bf6018-bdec-4565-913a-0746e018de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d2c18-1be5-4ee8-b8dd-315689373a4a",
   "metadata": {},
   "source": [
    "## Dependent Variables \n",
    "### Salmon viability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8081b268-bdfa-47fb-b7e1-3877a53d6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the salmon survival rate data from Perry et al (2021)\n",
    "Sal_viab = pd.read_excel('Data/ZooPlanktonPerryData.xlsx', sheet_name=5)\n",
    "\n",
    "Sal_viab = Sal_viab.rename(columns={'Ocean Entry Year':'Year'}).drop(columns=['Year'])\n",
    "\n",
    "# take logit of Sal_viab values, because these are proportions in (0,1)\n",
    "# this is done in the Perry et al paper too\n",
    "from scipy.special import logit, expit\n",
    "\n",
    "Sal_viab_logit = logit(Sal_viab).interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59673cc1-8ff8-4e44-9786-7ebbba42bf22",
   "metadata": {},
   "source": [
    "## Independent Variables\n",
    "### BC and WA regional populations and population trends, Port of Vancouver tonnage cargo, NPGO climate index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e99114-d763-4cb6-ae8c-26a7b5d982ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the population data for BC Regional Districts\n",
    "BC_pop = pd.read_csv('Data/BCPop1990.csv')#, index_col=0) # only need index_col=0 to make years the indices\n",
    "BC_pop = BC_pop.rename(columns={'Unnamed: 0':'Year'}).drop_duplicates() # there's a duplicate row at 2011!\n",
    "\n",
    "# pre-2001 BC population numbers are only for every five years\n",
    "# make an empty table for these years, to be interpolated\n",
    "missing_yrs = np.setdiff1d([i for i in range(1990,2001)],[1991,1996])\n",
    "missing_yrs_vals = np.empty((29,9,))*np.nan\n",
    "missing_data = np.vstack((missing_yrs,missing_yrs_vals)).transpose()\n",
    "BC_missing = pd.DataFrame(missing_data)\n",
    "BC_missing.columns = BC_pop.columns\n",
    "BC_pop = pd.concat([BC_missing,BC_pop]).sort_values(by='Year')\n",
    "\n",
    "# fill in the missing years with some linearly interpolated values where possible\n",
    "# and where this doesn't fill in a value, just repeat the closest value\n",
    "BC_pop = BC_pop.interpolate().bfill() \n",
    "# fix the indices obtained from concatenating\n",
    "BC_pop = BC_pop.reset_index().drop(columns=['index'])\n",
    "\n",
    "\n",
    "# import the population data for BC Regional Districts and WA Counties\n",
    "WA_pop = pd.read_csv('Data/WAPop1990.csv')# index_col=0)\n",
    "WA_pop = WA_pop.rename(columns={'Unnamed: 0':'Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "523a701e-33ab-41cc-852e-4612bc15a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC Group 1 average\n",
    "BC_1 = BC_pop.iloc[:,[3,7,9,10,12,14,18,20,25,28,29]]\n",
    "BC_1_avg = pd.DataFrame(BC_1.mean(axis=1), columns=['BC Gp1 Avg'])\n",
    "# BC Group 2 average\n",
    "BC_2 = BC_pop.iloc[:,[2,5,15,17,19]]\n",
    "BC_2_avg = pd.DataFrame(BC_2.mean(axis=1), columns=['BC Gp2 Avg'])\n",
    "# BC Group 3 average\n",
    "BC_3 = BC_pop.iloc[:,[6,8,11,13,16,22]]\n",
    "BC_3_avg = pd.DataFrame(BC_3.mean(axis=1),columns=['BC Gp3 Avg'])\n",
    "# BC Group 4 average\n",
    "BC_4 = BC_pop.iloc[:,[1,4,24,27]]\n",
    "BC_4_avg = pd.DataFrame(BC_4.mean(axis=1),columns=['BC Gp4 Avg'])\n",
    "# BC Group 5 average\n",
    "BC_5 = BC_pop.iloc[:,[21,23,26]]\n",
    "BC_5_avg = pd.DataFrame(BC_5.mean(axis=1),columns=['BC Gp5 Avg'])\n",
    "\n",
    "# WA Group 1 average\n",
    "WA_1 = WA_pop.iloc[:,[1,3,5,6,8,9,13,16,19,20,21,23,27,29,31,32,34,36,37,39]]\n",
    "WA_1_avg = pd.DataFrame(WA_1.mean(axis=1),columns=['WA Gp1 Avg'])\n",
    "# WA Group 2 average\n",
    "WA_2 = WA_pop.iloc[:,[2,4,18,22,24,25,26,28,30,33,35]]\n",
    "WA_2_avg = pd.DataFrame(WA_2.mean(axis=1),columns=['WA Gp2 Avg'])\n",
    "# WA Group 3 average\n",
    "WA_3 = WA_pop.iloc[:,[11,14,15,17,38]]\n",
    "WA_3_avg = pd.DataFrame(WA_3.mean(axis=1),columns=['WA Gp3 Avg'])\n",
    "# WA Group 4 average\n",
    "WA_4 = WA_pop.iloc[:,[7,10,12]]\n",
    "WA_4_avg = pd.DataFrame(WA_4.mean(axis=1),columns=['WA Gp4 Avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34eb588f-bba6-411e-a4bd-bf146a3b756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data on total tonnage of cargo through Port of Vancouver\n",
    "# years 2008-2023 are given in the Port Metro Vancouver Statistics Overviews at https://www.portvancouver.com/about-us/statistics/\n",
    "# years 1994-1998 are given in The Institutional Position of Seaports An International Comparison by Henrik Stevens, Chapter 7\n",
    "PortofVan = pd.DataFrame({'Year':[1994,1995,1996,1997,1998]+[i for i in range(2008,2023)],  \n",
    "                          'Tonnage':[67600000,71500000,72000000,73500000,71900000]+[114561990,101887824,118378885, \n",
    "                                122499631,123876885,135009878, \n",
    "                                139638157,138082585,135538055, \n",
    "                                142067550,147090934,144225630, \n",
    "                                145450722,146473626,141416326]})\n",
    "\n",
    "missing_yrs_port = pd.DataFrame({'Year':[1990,1991,1992,1993,1999,2000,2001,2002,2003,2004,2005,2006,2007],\n",
    "                               'Tonnage':[np.nan for _ in range(0,13)]})\n",
    "\n",
    "# linearly interpolate the port traffic data\n",
    "PortofVanExt = pd.concat([PortofVan,missing_yrs_port]).sort_values(by=['Year']).interpolate(method='linear', fill_value='extrapolate', limit_direction='both')\n",
    "PortofVanExt = PortofVanExt.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70924f48-9a29-4dd2-a3ae-aa05bd8172ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a climatological index\n",
    "NPGO_monthly = pd.read_csv('Data/NPGOMonthlyAvg copy.txt')\n",
    "\n",
    "# get the yearly NPGO averages and clean it up\n",
    "NPGO_yearly = NPGO_monthly.groupby('Year').mean()\n",
    "NPGO_yearly = NPGO_yearly.drop(columns=['Month']).reset_index()\n",
    "NPGO = NPGO_yearly.loc[(NPGO_yearly['Year']>=1990) & (NPGO_yearly['Year']<2023)]\n",
    "NPGO = NPGO.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed023124",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC_df = pd.concat([  BC_1_avg,\n",
    "                             BC_2_avg,\n",
    "                             BC_3_avg,\n",
    "                             BC_4_avg,\n",
    "                             BC_5_avg ]\n",
    "                  , axis=1)\n",
    "                   \n",
    "WA_df = pd.concat([ WA_1_avg,\n",
    "                             WA_2_avg,\n",
    "                             WA_3_avg ,\n",
    "                             WA_4_avg ]\n",
    "                  , axis=1)\n",
    "\n",
    "populations = pd.concat([WA_pop['Year'] , BC_df, WA_df ]  , axis=1) \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "436d9aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>BC Gp1 Avg</th>\n",
       "      <th>BC Gp2 Avg</th>\n",
       "      <th>BC Gp3 Avg</th>\n",
       "      <th>BC Gp4 Avg</th>\n",
       "      <th>BC Gp5 Avg</th>\n",
       "      <th>WA Gp1 Avg</th>\n",
       "      <th>WA Gp2 Avg</th>\n",
       "      <th>WA Gp3 Avg</th>\n",
       "      <th>WA Gp4 Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>239210.686699</td>\n",
       "      <td>25752.799952</td>\n",
       "      <td>57641.771741</td>\n",
       "      <td>35859.653528</td>\n",
       "      <td>21056.308168</td>\n",
       "      <td>138198.85</td>\n",
       "      <td>34745.090909</td>\n",
       "      <td>341584.6</td>\n",
       "      <td>4189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>239210.686699</td>\n",
       "      <td>25752.799952</td>\n",
       "      <td>57641.771741</td>\n",
       "      <td>35859.653528</td>\n",
       "      <td>21056.308168</td>\n",
       "      <td>142042.85</td>\n",
       "      <td>35751.727273</td>\n",
       "      <td>350711.6</td>\n",
       "      <td>4223.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>246979.926139</td>\n",
       "      <td>25950.319928</td>\n",
       "      <td>58710.597327</td>\n",
       "      <td>36439.583717</td>\n",
       "      <td>21182.764974</td>\n",
       "      <td>144950.55</td>\n",
       "      <td>36598.181818</td>\n",
       "      <td>355353.8</td>\n",
       "      <td>4259.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year     BC Gp1 Avg    BC Gp2 Avg    BC Gp3 Avg    BC Gp4 Avg  \\\n",
       "0  1990  239210.686699  25752.799952  57641.771741  35859.653528   \n",
       "1  1991  239210.686699  25752.799952  57641.771741  35859.653528   \n",
       "2  1992  246979.926139  25950.319928  58710.597327  36439.583717   \n",
       "\n",
       "     BC Gp5 Avg  WA Gp1 Avg    WA Gp2 Avg  WA Gp3 Avg   WA Gp4 Avg  \n",
       "0  21056.308168   138198.85  34745.090909    341584.6  4189.000000  \n",
       "1  21056.308168   142042.85  35751.727273    350711.6  4223.000000  \n",
       "2  21182.764974   144950.55  36598.181818    355353.8  4259.333333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>NPGO index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>-0.201546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991.0</td>\n",
       "      <td>-0.498915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992.0</td>\n",
       "      <td>-1.094919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  NPGO index\n",
       "0  1990.0   -0.201546\n",
       "1  1991.0   -0.498915\n",
       "2  1992.0   -1.094919"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Tonnage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>67600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>67600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>67600000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year     Tonnage\n",
       "0  1990  67600000.0\n",
       "1  1991  67600000.0\n",
       "2  1992  67600000.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(populations.head(3))\n",
    "display(NPGO.head(3))\n",
    "display(PortofVanExt.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf25c2c",
   "metadata": {},
   "source": [
    "# Aycin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7e92460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f7e82",
   "metadata": {},
   "source": [
    "Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4de76eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Years we concerned with \n",
    "start_year=1990\n",
    "end_year=2017\n",
    "year_range = range(start_year, end_year+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672868eb",
   "metadata": {},
   "source": [
    " Target Data - Salmon Survivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "589df7e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Read ZooPlanktonPerryData file\n",
    "##obtain SalmonSurvivals_data\n",
    "            #Take years less than or equal to 2017\n",
    "                            #last row (year 2018) has only NaN\n",
    "\n",
    "\n",
    "file_path = \"Data/ZooPlanktonPerryData.xlsx\"\n",
    "selected_sheet = \"5. Salmon marine survivals\"  \n",
    "df = pd.read_excel(file_path, sheet_name=selected_sheet)\n",
    "SalmonSurvivals_data = df[df[\"Ocean Entry Year\"]<=2017]\n",
    "\n",
    "\n",
    "#Rename the columns \n",
    "abbreviation_mapping = {\n",
    "    'Ocean Entry Year': 'year',\n",
    "    'Cowichan Chinook': 'Cow_Ch',\n",
    "    'Harrison Chinook': 'Har_Ch',\n",
    "    'Puntledge Chinook': 'Pun_Ch',\n",
    "    'Big Qualicum Coho': 'BQ_Coho'\n",
    "}\n",
    "\n",
    "salmonSurvivals = SalmonSurvivals_data.rename(columns=abbreviation_mapping)\n",
    "\n",
    "\n",
    "# List of salmon types \n",
    "year_column = 'year'\n",
    "salmonTypes_List =  [col for col in salmonSurvivals.columns if col != year_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505320eb",
   "metadata": {},
   "source": [
    "Data Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01567a6",
   "metadata": {},
   "source": [
    "Total Zooplankton Biomasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a27f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ZooPlanktonPerryData file\n",
    "\n",
    "##obtain  plankBiomass_data   \n",
    "###take the years less than 2017 \n",
    "###we drop columns that do not give biomass of zooplanktons\n",
    "file_path = \"Data/ZooPlanktonPerryData.xlsx\"\n",
    "selected_sheet = \"1. Zooplankton Biomass data\"  \n",
    "df = pd.read_excel(file_path, sheet_name=selected_sheet)\n",
    "df= df[df[\"yr\"]<=2017]\n",
    "plankBiomass_data=df.drop(columns=['key', 'survey', 'region', 'event', 'net', 'station', 'lon', 'lat', 'mon', 'day', 'time',  'twilight', 'net.type', 'diam.m', 'mesh.um', 'startz.m', 'endz.m','botz.m',\n",
    "       'volfilt.m3'])\n",
    "\n",
    "##  BiomassDefs      (if info on column names is needed)\n",
    "selected_sheet = \"2. Biomass data definitions\"  \n",
    "BiomassDefs = pd.read_excel(file_path, sheet_name=selected_sheet)\n",
    "\n",
    "\n",
    "\n",
    "## Create a new DataFrame which contains years and corresponding total biomasses mean\n",
    "#Calculate average Total Biomass for each year inside the common year range\n",
    "#drop duplicates\n",
    "#reset index\n",
    "\n",
    "totalBiomass_av= pd.DataFrame()\n",
    "\n",
    "totalBiomass_av['year']= plankBiomass_data['yr']\n",
    "totalBiomass_av['Av_totalBiomass']= plankBiomass_data.groupby('yr')['Total.Biomass'].transform('mean')\n",
    "totalBiomass_av.drop_duplicates(inplace=True)\n",
    "totalBiomass_av.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Create a new DataFrame for averaged values\n",
    "#Group by 'yr' and calculate the annual mean of Zooplanktons\n",
    "#drop duplicates\n",
    "#rename the columns for convenienve\n",
    "#reset_index\n",
    "\n",
    "plankBiomassMean = pd.DataFrame()\n",
    "\n",
    "for column in plankBiomass_data.columns:\n",
    "    if column in ['yr', 'region']:\n",
    "        plankBiomassMean[column] = plankBiomass_data[column]\n",
    "    else:\n",
    "        name = 'Av_' + column\n",
    "        plankBiomassMean[name] = plankBiomass_data.groupby('yr')[column].transform('mean')\n",
    "\n",
    "\n",
    "plankBiomassMean.drop_duplicates(subset=['yr'], inplace=True)\n",
    "plankBiomassMean.rename(columns={'yr': 'year', 'Av_Total.Biomass': 'Av_totalBiomass'},  inplace=True)\n",
    "plankBiomassMean.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616dfc0",
   "metadata": {},
   "source": [
    "### Obtained Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ebb5e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Av_AmphiGam</th>\n",
       "      <th>Av_AmphiHyp</th>\n",
       "      <th>Av_BenthicLarv</th>\n",
       "      <th>Av_CalCops.larg</th>\n",
       "      <th>Av_CalCops.med</th>\n",
       "      <th>Av_CalCops.smal</th>\n",
       "      <th>Av_Cephalopoda</th>\n",
       "      <th>Av_Chaetognatha</th>\n",
       "      <th>Av_Cladocera</th>\n",
       "      <th>...</th>\n",
       "      <th>Av_Natantia</th>\n",
       "      <th>Av_NonCalCops</th>\n",
       "      <th>Av_Ostracoda</th>\n",
       "      <th>Av_Other</th>\n",
       "      <th>Av_PolychaetPelagic</th>\n",
       "      <th>Av_Pteropods</th>\n",
       "      <th>Av_Repantia</th>\n",
       "      <th>Av_Scyphozoa</th>\n",
       "      <th>Av_Siphonophorae</th>\n",
       "      <th>Av_totalBiomass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996</td>\n",
       "      <td>3.099832</td>\n",
       "      <td>1.324307</td>\n",
       "      <td>0.274767</td>\n",
       "      <td>13.213023</td>\n",
       "      <td>9.285405</td>\n",
       "      <td>0.929795</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>0.358527</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718163</td>\n",
       "      <td>0.322313</td>\n",
       "      <td>2.674950</td>\n",
       "      <td>0.083352</td>\n",
       "      <td>1.615180</td>\n",
       "      <td>0.324095</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531088</td>\n",
       "      <td>37.388238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>8.415328</td>\n",
       "      <td>1.458525</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>24.451942</td>\n",
       "      <td>9.381715</td>\n",
       "      <td>0.810660</td>\n",
       "      <td>0.022965</td>\n",
       "      <td>1.561735</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606682</td>\n",
       "      <td>0.358207</td>\n",
       "      <td>3.035919</td>\n",
       "      <td>0.041017</td>\n",
       "      <td>0.437920</td>\n",
       "      <td>0.482410</td>\n",
       "      <td>4.063566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431464</td>\n",
       "      <td>71.212723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>8.007227</td>\n",
       "      <td>3.214592</td>\n",
       "      <td>0.572927</td>\n",
       "      <td>12.494889</td>\n",
       "      <td>11.405672</td>\n",
       "      <td>1.033331</td>\n",
       "      <td>0.053075</td>\n",
       "      <td>0.980033</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637259</td>\n",
       "      <td>0.325437</td>\n",
       "      <td>3.960144</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.897803</td>\n",
       "      <td>2.674066</td>\n",
       "      <td>0.688282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202136</td>\n",
       "      <td>105.522363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  Av_AmphiGam  Av_AmphiHyp  Av_BenthicLarv  Av_CalCops.larg  \\\n",
       "0  1996     3.099832     1.324307        0.274767        13.213023   \n",
       "1  1997     8.415328     1.458525        0.033581        24.451942   \n",
       "2  1998     8.007227     3.214592        0.572927        12.494889   \n",
       "\n",
       "   Av_CalCops.med  Av_CalCops.smal  Av_Cephalopoda  Av_Chaetognatha  \\\n",
       "0        9.285405         0.929795        0.015525         0.358527   \n",
       "1        9.381715         0.810660        0.022965         1.561735   \n",
       "2       11.405672         1.033331        0.053075         0.980033   \n",
       "\n",
       "   Av_Cladocera  ...  Av_Natantia  Av_NonCalCops  Av_Ostracoda  Av_Other  \\\n",
       "0      0.000955  ...     0.718163       0.322313      2.674950  0.083352   \n",
       "1      0.006467  ...     0.606682       0.358207      3.035919  0.041017   \n",
       "2      0.010478  ...     0.637259       0.325437      3.960144  0.004294   \n",
       "\n",
       "   Av_PolychaetPelagic  Av_Pteropods  Av_Repantia  Av_Scyphozoa  \\\n",
       "0             1.615180      0.324095     0.081970           0.0   \n",
       "1             0.437920      0.482410     4.063566           0.0   \n",
       "2             0.897803      2.674066     0.688282           0.0   \n",
       "\n",
       "   Av_Siphonophorae  Av_totalBiomass  \n",
       "0          0.531088        37.388238  \n",
       "1          0.431464        71.212723  \n",
       "2          0.202136       105.522363  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Av_totalBiomass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996</td>\n",
       "      <td>37.388238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>71.212723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>105.522363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  Av_totalBiomass\n",
       "0  1996        37.388238\n",
       "1  1997        71.212723\n",
       "2  1998       105.522363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(plankBiomassMean.head(3))\n",
    "display(totalBiomass_av.head(3))\n",
    "#Note: data of totalBiomass_av appears in plankBiomassMean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa86d13",
   "metadata": {},
   "source": [
    "Sea Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff07243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the Annual Mean Sea Levels\n",
    "        #there are data of four ports\n",
    "#Take the years between start_year and end_year\n",
    "#Take the positive values (non existent data entered as -99999\n",
    "#drop the columns 2 and 3 to keep year and sea level measurement\n",
    "#rename the column that contains Sea Level measurement\n",
    "\n",
    "\n",
    "file_path=\"Data/SeaLevel_Point_Atkinson193.txt\"\n",
    "df=pd.read_csv(file_path, header=None,delimiter=';')\n",
    "df= df[(df[0] >= start_year) & (df[0] <= end_year) & (df[1]>=0)].drop(columns=[2,3])\n",
    "seaLevelPointA_clean =df.rename(columns={0: 'year', 1: 'SeaLevel_Point_Atkinson'})\n",
    "#missing year 1997\n",
    "\n",
    "file_path=\"Data/SeaLevel_Port_Angeles2127.txt\"\n",
    "df =pd.read_csv(file_path, header=None,delimiter=';')\n",
    "df= df[(df[0] >= start_year) & (df[0] <= end_year) & (df[1]>=0)].drop(columns=[2,3])\n",
    "seaLevelPortA_clean= df.rename(columns={0: 'year', 1: 'SeaLevel_Port_Angeles'})\n",
    "#no missing year\n",
    "\n",
    "file_path=\"Data/SeaLevel_Campbell_River1323.txt\"\n",
    "df=pd.read_csv(file_path, header=None,delimiter=';')\n",
    "df= df[(df[0] >= start_year) & (df[0] <= end_year) & (df[1]>=0)].drop(columns=[2,3])\n",
    "seaLevelCampbellR_clean= df.rename(columns={0: 'year', 1: 'SeaLevel_Campbell_River'})\n",
    "#missing year 1995 & 1996\n",
    "\n",
    "file_path=\"Data/SeaLevel_Cherry_annualMean.txt\"\n",
    "df= pd.read_csv(file_path, header=None,delimiter=';')\n",
    "df= df[(df[0] >= start_year) & (df[0] <= end_year) & (df[1]>=0)].drop(columns=[2,3])\n",
    "seaLevelCherryP_clean= df.rename(columns={0: 'year', 1: 'SeaLevel_Cherry'})\n",
    "#missing year 1994\n",
    "\n",
    "\n",
    "#Merge the sea Levels\n",
    "#Calculate their average \n",
    "    #missing data is ignored \n",
    "        #note: if a year is missing it's only missing at most one of the ports\n",
    "\n",
    "merged_df= pd.merge(seaLevelPortA_clean, seaLevelPointA_clean, on='year', how='outer')\n",
    "merged_df = pd.merge(merged_df, seaLevelCampbellR_clean, on='year', how='outer')\n",
    "seaLevels = pd.merge(merged_df, seaLevelCherryP_clean, on='year', how='outer')\n",
    "\n",
    "seaLevels['av_SeaLevels']= seaLevels.iloc[:,1:].mean(axis=1, skipna=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa84082",
   "metadata": {},
   "source": [
    "### Obtained Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d557e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seaLevels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5aa37",
   "metadata": {},
   "source": [
    "# Observed Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a213631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Cowichan Chinook', 'Harrison Chinook', 'Puntledge Chinook',\n",
       "       'Big Qualicum Coho', 'SST Jan.', 'SST Feb.', 'SST Mar.', 'SST Apr.',\n",
       "       'SST May', 'SST Jun.', 'SST Jul.', 'SST Aug', 'SST Sep.', 'SST Oct.',\n",
       "       'SST Nov.', 'SST Dec.', 'TotBiom', 'AmphiGam', 'AmphiHyp',\n",
       "       'BenthicLarv', 'CalCops.larg', 'CalCops.med', 'CalCops.smal',\n",
       "       'Chaetognatha', 'Cladocera', 'Ctenophora', 'Euphs', 'Fish', 'Larvacea',\n",
       "       'Medusae', 'Natantia', 'NonCalCops', 'Ostracoda', 'PolychaetPelagic',\n",
       "       'Pteropods', 'Repantia', 'Siphonophorae', 'Coho', 'Chinook',\n",
       "       'Sea Level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllDataNoNull.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "228a0da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Avg Sea Salinity', 'pdo', 'Max flow rate', 'Min flow rate',\n",
       "       'Avg flow rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_env_factors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0094d497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Harbour seal', 'Killer whale'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_factors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70c62793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_input_variables merges the above two \n",
    "                                #df_env_factors and df_pred_factors\n",
    "# df_input_variables.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea590826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'BC Gp1 Avg', 'BC Gp2 Avg', 'BC Gp3 Avg', 'BC Gp4 Avg',\n",
       "       'BC Gp5 Avg', 'WA Gp1 Avg', 'WA Gp2 Avg', 'WA Gp3 Avg', 'WA Gp4 Avg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populations.columns\n",
    "#merges BC_df, WA_df and 'Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f197172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'NPGO index'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NPGO.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3faac5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Tonnage'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PortofVanExt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11bc2c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'Av_AmphiGam', 'Av_AmphiHyp', 'Av_BenthicLarv',\n",
       "       'Av_CalCops.larg', 'Av_CalCops.med', 'Av_CalCops.smal',\n",
       "       'Av_Cephalopoda', 'Av_Chaetognatha', 'Av_Cladocera', 'Av_Ctenophora',\n",
       "       'Av_Euphs', 'Av_Fish', 'Av_Larvacea', 'Av_Medusae', 'Av_Mysids',\n",
       "       'Av_Natantia', 'Av_NonCalCops', 'Av_Ostracoda', 'Av_Other',\n",
       "       'Av_PolychaetPelagic', 'Av_Pteropods', 'Av_Repantia', 'Av_Scyphozoa',\n",
       "       'Av_Siphonophorae', 'Av_totalBiomass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plankBiomassMean.columns\n",
    "# totalBiomass_av is 'Av_totalBiomass' the same as plankBiomassMean[['year', 'Av_totalBiomass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "060eadee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'SeaLevel_Port_Angeles', 'SeaLevel_Point_Atkinson',\n",
       "       'SeaLevel_Campbell_River', 'SeaLevel_Cherry', 'av_SeaLevels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seaLevels.columns\n",
    "###Some columns contain NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301eda8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
